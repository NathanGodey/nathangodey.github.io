<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://nathangodey.github.io/</id><title>Nathan Godey</title><subtitle>Blog posts, material, and some other stuff.</subtitle> <updated>2024-04-25T23:59:47+02:00</updated> <author> <name>Nathan Godey</name> <uri>https://nathangodey.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://nathangodey.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="en" href="https://nathangodey.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator> <rights> © 2024 Nathan Godey </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>Chinchilla Scaling Laws Calculator</title><link href="https://nathangodey.github.io/posts/scaling/" rel="alternate" type="text/html" title="Chinchilla Scaling Laws Calculator" /><published>2023-12-18T14:00:00+01:00</published> <updated>2023-12-20T11:40:05+01:00</updated> <id>https://nathangodey.github.io/posts/scaling/</id> <content src="https://nathangodey.github.io/posts/scaling/" /> <author> <name>me</name> </author> <category term="logbook" /> <summary> Simple Chinchilla Calculator Enter a model size (in M, without embeddings): Get training tokens How many tokens should we train with? If you look for material about scaling laws online, you will either find rather technical material close to the original paper, or very vague simplifications. I have not found something l... </summary> </entry> <entry><title>MANTa: Efficient Gradient-Based Tokenization for End-to-End Robust Language Modeling</title><link href="https://nathangodey.github.io/posts/manta/" rel="alternate" type="text/html" title="MANTa: Efficient Gradient-Based Tokenization for End-to-End Robust Language Modeling" /><published>2023-06-09T15:00:00+02:00</published> <updated>2023-06-09T15:00:00+02:00</updated> <id>https://nathangodey.github.io/posts/manta/</id> <content src="https://nathangodey.github.io/posts/manta/" /> <author> <name>me</name> </author> <category term="logbook" /> <summary> Last year, I got my first paper published as a findings at EMNLP 2022! It was a joint effort with Roman Castagné and was co-authored by my PhD supervisors Eric Villemonte de la Clergerie and Benoît Sagot from Inria’s ALMAnaCH team. It introduces a differentiable tokenization that can be plugged to many language models to make end-to-end neural language modeling. Here is the PDF version of the... </summary> </entry> <entry><title>How word frequency affects language models</title><link href="https://nathangodey.github.io/posts/frequency_lm/" rel="alternate" type="text/html" title="How word frequency affects language models" /><published>2023-03-13T14:00:00+01:00</published> <updated>2023-03-13T15:53:25+01:00</updated> <id>https://nathangodey.github.io/posts/frequency_lm/</id> <content src="https://nathangodey.github.io/posts/frequency_lm/" /> <author> <name>me</name> </author> <category term="logbook" /> <summary> As I started my PhD a few months ago, I believed that contextual embeddings coming from pre-trained language models aimed at representing words in a vector space as humans might in their thought process. In other words, I thought the BERT-like embedding spaces tended to learn the underlying metric of word relatedness depending on context. To the impish, this belief is easy to catch because of ... </summary> </entry> </feed>
